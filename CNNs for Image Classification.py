# -*- coding: utf-8 -*-
"""Copy of 01_Keras_CNN_MNIST_ClassActivity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vNe0CeCzB5zYTeuFJugViHnUfJWFkU5W

# Convolutional Neural Networks for Image Classification

Overview:
This guide outlines the process of using a convolutional neural network (CNN) for classifying images from the MNIST dataset. Each step is designed to help you understand the architecture of CNNs and the role of data preprocessing.

# **From Keras datasets import mnist**
"""

from keras.datasets import mnist
(X_train, y_train), (X_test, y_test)= mnist.load_data()

# Print the classes
classes = sorted(set(y_test))
print("Classes in MNIST dataset:", classes)

"""##  Visualizing the Image Data

# **import matplotlib.pyplot as plt**
"""

print("Training set shape:", X_train.shape)
print("Test set shape:", X_test.shape)
print("Traning set shape:", y_train.shape)
print("Test set labels:", y_test.shape)

#import matplotlib here
import matplotlib.pyplot as plt


# Display the first 5 images with their labels
for i in range(5):
    plt.subplot(1, 5, i+1)  # Create subplots
    plt.imshow(X_train[i], cmap="gray")  # Show the image
    plt.title(f"Label: {y_train[i]}")
    plt.axis('off')

plt.show()

# Display the figure
plt.show()

"""# **Check the shape of the data**"""

print("Original shape of X_train:", X_train.shape)
#total check of the x_train shape
#we will have to reshape this

"""# **check the first image of the dataset**"""

X_train[0][0][0]

"""Check Single Image

## **Note: more values are zero because the image is mostly white**
"""

for i in range(20):
  print(X_train[i][i][i])
#more values are zero because the image is mostly white

"""**Check single image shape**
Grayscale image so only one channel
"""

single_image=X_train[0]
#grayscale image

"""Now show the single image here"""

#has a specific way to showing (Once we get into OpenCV then we can get into this)

plt.imshow(single_image, cmap='gray')

"""# PreProcessing Data

We first need to make sure the labels will be understandable by our CNN.

## Labels
"""

y_train
#network will think these are values and this is a regression problem

y_test

"""Hmmm, looks like our labels are literally categories of numbers. We need to translate this to be "one hot encoded" so our CNN can understand, otherwise it will think this is some sort of regression problem on a continuous axis. Luckily , Keras has an easy to use function for this:

USE THE BELOW GIVEN CODE AS IT IS
"""

from tensorflow.keras.utils import to_categorical

"""Show y_train shape here (Hint: it should be 60000)"""

y_train.shape

"""*Here* we will be converting the y_train labels of the dataset into a one-hot encoded format using Keras's to_categorical function."""

#Hint lable name --- (y_example) = to_categorical(y_train)

y_cat_train = to_categorical(y_train, num_classes=10)

print("Shape of y_cat_train:", y_cat_train.shape)

# Check an example
print("First label before encoding:", y_train[0])  # e.g., 5
print("First label after encoding:", y_cat_train[0])

"""**Show your y_example here**"""

y_cat_train

"""Show your y_example shape here (Hint: it should be 60000,10)"""

y_cat_train.shape

"""Check first array = (Hint: y_example[0])"""

y_cat_train[0]

"""# Convert the integer labels from the test set into a one-hot format.
# 'to_categorical' function is used here to achieve this transformation.
# The second parameter '10' indicates the total number of classes, which are 0-9.
"""

y_cat_test = to_categorical(y_test,10)
#0-9 are the possible results so 10 possible classes

"""# This conversion allows the model to handle this as a classification problem rather than a regression one.

# Similarly, convert the integer labels from the training set into a one-hot format.
# Ensuring that both training and test labels are processed in the same way for consistent model training.
"""

y_cat_train.shape

"""# To understand the result of our one-hot encoding, we will display the one-hot encoded labels for the first sample in the training set.
# This will show a binary vector where one element is '1' indicating the class, and '0's indicating non-membership of other classes.
# Example: For a class label 3, the output will be [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].
# Show the result of one-hot encoding for the first training label
"""

#Show the result of one hot encoding
y_cat_train[0]

"""### Processing X Data

We should normalize the X data manually
Feel more confident if you need to do it yourself

# Check the maximum pixel value in an image from the dataset.
# This is typically 255 for images stored in 8-bit format.
"""

max_pixel_value = X_train.max()
print(f"Maximum pixel value in the training set: {max_pixel_value}")

"""# Check the minimum pixel value in the same image.
# This is typically 0, indicating no intensity (black).
"""

min_pixel_value = X_train.min()
print(f"Minimum pixel value in the training set: {min_pixel_value}")

"""# Normalize the pixel values of the training and test datasets to a range of 0 to 1.
# Dividing by 255 as the original range is from 0 to 255.
# This normalization helps in faster convergence during training.
"""

X_train = X_train / 255.0
X_test = X_test / 255.0

"""# Store the normalized version of the first training image to a variable for further examination."""

X_train[0]

"""# Check the maximum pixel value in the normalized image.
# The result should be 1.0, indicating that pixel values are now between 0 and 1.
"""

max_pixel_value = X_train.max()
print(f"Maximum pixel value in the training set: {max_pixel_value}")

"""Uncomment the first line of code and run"""

plt.imshow(X_test[0])
#no visual difference

"""## Reshaping the Data

Right now our data is 60,000 images stored in 28 by 28 pixel array formation.

This is correct for a CNN, but we need to add one more dimension to show we're dealing with 1 RGB channel (since technically the images are in black and white, only showing values from 0-255 on a single channel), an color image would have 3 dimensions.

We want to make generalized network with can work any set of images so we need add color channel.
"""

X_train.shape

X_test.shape

"""Reshape to include channel dimension (in this case, 1 channel)

# Reshape the training data to include a channel dimension.
# This is necessary for Keras to process the data correctly in convolutional layers.
# The MNIST images are grayscale, so the channel dimension is 1.
# Reshape parameters: (number of images, height, width, number of channels)
"""

X_train= X_train.reshape((X_train.shape[0], 28, 28, 1))

"""# Confirm the new shape of the training data.
# Expected shape: (60000, 28, 28, 1), which means there are 60,000 images, each 28x28 in size, with 1 color channel.
"""

X_train.shape

X_test = X_test.reshape(10000,28,28,1)

X_test.shape

"""# Training the Model

# Import necessary layers from Keras to build the CNN
"""

from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D, Flatten

"""# Initialize a sequential model to add layers in a feed-forward manner

# Add a convolutional layer:
# - 32 filters for extracting features, with a kernel size of (4x4) to process the input images
# - 'input_shape' should match the shape of the reshaped input data (28x28 images with 1 color channel)
# - 'relu' activation function is used to introduce non-linearity to the learning process
"""

from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam

mlp_model = models.Sequential(name="MLP_model")

# CONVOLUTIONAL LAYER
mlp_model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(28, 28, 1), activation='relu',))
# POOLING LAYER
mlp_model.add(layers.MaxPooling2D((4, 4)))

# FLATTEN IMAGES FROM 28 by 28 to 764 BEFORE FINAL LAYER
mlp_model.add(layers.Flatten())

# 128 NEURONS IN DENSE HIDDEN LAYER (YOU CAN CHANGE THIS NUMBER OF NEURONS)
mlp_model.add(layers.Dense(128, activation='relu'))

# LAST LAYER IS THE CLASSIFIER, THUS 10 POSSIBLE CLASSES
mlp_model.add(layers.Dense(10, activation='softmax'))



mlp_model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

"""Check Model Summary"""

mlp_model.summary()

"""## Train the Model

Model train on only 2 epochs
"""

# THIS WILL TAKE AWHILE ON MOST COMPUTERS!!!
# CHANGE NUMBER OF EPOCHS IF NECESSARY
# YOUR ACCURACY MAY ALSO BE LOWER THAN WHAT IS SHOWN HERE SINCE THIS WAS TRAINED ON GPU


mlp_model.fit(X_train,y_cat_train,epochs=12)

"""## Evaluate the Model"""

mlp_model.metrics_names

mlp_model.evaluate(X_test,y_cat_test)

from sklearn.metrics import classification_report

import numpy as np

predictions_mlp = mlp_model.predict(X_test)
predicted_labels_mlp = np.argmax(predictions_mlp, axis=1)



# Assuming you have already defined and trained your model

y_cat_test.shape

y_cat_test[0]

predictions[0]

predicted_classes[0]

y_test

from sklearn.metrics import classification_report


report = classification_report(y_test, predicted_labels_mlp)

# Print the classification report
print(report)

"""Looks like the CNN performed quite well!"""